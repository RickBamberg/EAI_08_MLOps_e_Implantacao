{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScript respons√°vel por gerar os artefatos oficiais do modelo v1.\\nEste script deve ser executado apenas uma vez para congelamento da vers√£o.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script respons√°vel por gerar os artefatos oficiais do modelo v1.\n",
    "Este script deve ser executado apenas uma vez para congelamento da vers√£o.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, f1_score, \n",
    "    precision_score, recall_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Carregando dados...\n",
      "   Shape original: (594643, 10)\n",
      "‚úÖ Dados limpos: (594643, 10)\n",
      "   Normal: 587,443 | Fraude: 7,200\n"
     ]
    }
   ],
   "source": [
    "os.chdir('src')\n",
    "ARTIFACT_PATH = \"../artifacts/model_v1/\"\n",
    "from data.load_data import carregar_dados\n",
    "df = carregar_dados(\"../data/raw/v1/bs140513_032310.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o da vari√°vel target\n",
    "fraud_counts = df['fraud'].value_counts().sort_index()\n",
    "fraud_pct = df['fraud'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "for value in sorted(df['fraud'].unique()):\n",
    "    count = fraud_counts[value]\n",
    "    pct = fraud_pct[value]\n",
    "    label = 'Normal' if value == 0 else 'Fraude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma c√≥pia do dataframe para feature engineering\n",
    "df_features = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. FEATURES BASEADAS NO CLIENTE\n",
    "# ============================================================================\n",
    "\n",
    "# Frequ√™ncia de transa√ß√µes por cliente no mesmo step\n",
    "freq_step = (\n",
    "    df_features.groupby(['step', 'customer'])\n",
    "    .size()\n",
    "    .reset_index(name='qtd_transacoes')\n",
    ")\n",
    "df_features = df_features.merge(freq_step, on=['step', 'customer'])\n",
    "df_features['alert_freq'] = (df_features['qtd_transacoes'] > 3).astype(int)\n",
    "\n",
    "# Perfil de valor por cliente (m√©dia e desvio padr√£o)\n",
    "stats_cliente = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "stats_cliente.columns = ['customer', 'amount_mean_cliente', 'amount_std_cliente']\n",
    "df_features = df_features.merge(stats_cliente, on='customer')\n",
    "df_features['amount_std_cliente'].fillna(0, inplace=True)\n",
    "df_features['alert_valor'] = (\n",
    "    df_features['amount'] > (df_features['amount_mean_cliente'] + 3 * df_features['amount_std_cliente'])\n",
    ").astype(int)\n",
    "\n",
    "# Valor relativo √† m√©dia do cliente\n",
    "df_features['valor_relativo_cliente'] = df_features['amount'] / (df_features['amount_mean_cliente'] + 1e-6)\n",
    "\n",
    "# Total de transa√ß√µes por cliente\n",
    "df_features['total_tx_cliente'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "# Volume total gasto pelo cliente\n",
    "df_features['volume_total_cliente'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform('sum')\n",
    ")\n",
    "\n",
    "# Diversidade de categorias por cliente\n",
    "df_features['num_categorias_cliente'] = (\n",
    "    df_features.groupby('customer')['category']\n",
    "    .transform('nunique')\n",
    ")\n",
    "\n",
    "# Diversidade de merchants por cliente\n",
    "df_features['num_merchants_cliente'] = (\n",
    "    df_features.groupby('customer')['merchant']\n",
    "    .transform('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. FEATURES TEMPORAIS\n",
    "# ============================================================================\n",
    "\n",
    "# Ordenando por cliente e step\n",
    "df_features = df_features.sort_values(['customer', 'step']).reset_index(drop=True)\n",
    "\n",
    "# Transa√ß√µes nos √∫ltimos 5 steps\n",
    "df_features['tx_ultimos_5_steps'] = (\n",
    "    df_features.groupby('customer')['step']\n",
    "    .transform(lambda x: x.rolling(5, min_periods=1).count())\n",
    ")\n",
    "\n",
    "# Tempo desde a √∫ltima transa√ß√£o\n",
    "df_features['step_diff'] = (\n",
    "    df_features.groupby('customer')['step']\n",
    "    .diff()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# M√©dia de valor dos √∫ltimos 5 steps\n",
    "df_features['amount_media_5steps'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Desvio do valor atual em rela√ß√£o aos √∫ltimos 5 steps\n",
    "df_features['amount_desvio_5steps'] = (\n",
    "    df_features['amount'] - df_features['amount_media_5steps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. FEATURES DE RELACIONAMENTO CLIENTE-MERCHANT\n",
    "# ============================================================================\n",
    "\n",
    "# Frequ√™ncia do par cliente-merchant\n",
    "df_features['tx_cliente_merchant'] = (\n",
    "    df_features.groupby(['customer', 'merchant'])['amount']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "# √â a primeira transa√ß√£o deste cliente com este merchant?\n",
    "df_features['primeira_tx_merchant'] = (\n",
    "    df_features['tx_cliente_merchant'] == 1\n",
    ").astype(int)\n",
    "\n",
    "# Propor√ß√£o de transa√ß√µes do cliente neste merchant\n",
    "df_features['prop_tx_merchant'] = (\n",
    "    df_features['tx_cliente_merchant'] / df_features['total_tx_cliente']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. FEATURES DE LOCALIZA√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Mesma localiza√ß√£o?\n",
    "df_features['mesma_localizacao'] = (\n",
    "    df_features['zipcodeOri'] == df_features['zipMerchant']\n",
    ").astype(int)\n",
    "\n",
    "# N√∫mero de diferentes localiza√ß√µes do cliente\n",
    "df_features['num_zipcodes_cliente'] = (\n",
    "    df_features.groupby('customer')['zipcodeOri']\n",
    "    .transform('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding de vari√°veis categ√≥ricas\n",
    "le_gender = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "\n",
    "df_features['gender_encoded'] = le_gender.fit_transform(df_features['gender'])\n",
    "df_features['category_encoded'] = le_category.fit_transform(df_features['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando features para o modelo\n",
    "features_to_use = [\n",
    "    # Features originais\n",
    "    'step', 'age', 'gender_encoded', 'category_encoded', 'amount',\n",
    "    \n",
    "    # Features engineered - Cliente\n",
    "    'qtd_transacoes', 'alert_freq', 'alert_valor', 'valor_relativo_cliente',\n",
    "    'total_tx_cliente', 'volume_total_cliente', 'num_categorias_cliente',\n",
    "    'num_merchants_cliente', 'amount_mean_cliente', 'amount_std_cliente',\n",
    "    \n",
    "    # Features temporais\n",
    "    'tx_ultimos_5_steps', 'step_diff', 'amount_media_5steps', 'amount_desvio_5steps',\n",
    "    \n",
    "    # Features merchant\n",
    "    #'tx_por_merchant_train', 'fraude_merchant_train', 'amount_mean_merchant'\n",
    "     'amount_std_merchant',\n",
    "    \n",
    "    # Features relacionamento\n",
    "    'tx_cliente_merchant', 'primeira_tx_merchant', 'prop_tx_merchant',\n",
    "    \n",
    "    # Features localiza√ß√£o\n",
    "    'mesma_localizacao', 'num_zipcodes_cliente',\n",
    "    \n",
    "    # Features categoria\n",
    "    #'fraude_categoria'\n",
    "     'amount_mean_categoria', 'amount_desvio_categoria',\n",
    "    \n",
    "    # Scores\n",
    "    'qtd_alertas', 'score_regra'\n",
    "]\n",
    "\n",
    "# Verificar se todas as features existem\n",
    "missing_features = [f for f in features_to_use if f not in df_features.columns]\n",
    "if missing_features:\n",
    "    features_to_use = [f for f in features_to_use if f in df_features.columns]\n",
    "\n",
    "X = df_features[features_to_use].copy()\n",
    "y = df_features['fraud'].copy()\n",
    "\n",
    "# Garantir que X cont√©m apenas valores num√©ricos\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Substituir inf e -inf por NaN\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Preencher NaN com 0\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/teste com estratifica√ß√£o\n",
    "from models.v1.base_model import split_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o das features\n",
    "from models.v1.scaler import scaler_data\n",
    "\n",
    "X_train_scaled, X_test_scaled, scaler = scaler_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem de Machine Learning¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Treinando: Gradient Boosting\n",
      "============================================================\n",
      "\n",
      "M√©tricas no conjunto de teste:\n",
      "  Precision: 0.9180\n",
      "  Recall:    0.8007\n",
      "  F1-Score:  0.8553\n",
      "  ROC-AUC:   0.9982\n",
      "  Tempo (1000): 611.3882s\n",
      "\n",
      "Matriz de Confus√£o:\n",
      "[[117386    103]\n",
      " [   287   1153]]\n",
      "\n",
      "Relat√≥rio de Classifica√ß√£o:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    117489\n",
      "      Fraude       0.92      0.80      0.86      1440\n",
      "\n",
      "    accuracy                           1.00    118929\n",
      "   macro avg       0.96      0.90      0.93    118929\n",
      "weighted avg       1.00      1.00      1.00    118929\n",
      "\n",
      "‚úÖ Fun√ß√£o de avalia√ß√£o criada!\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from models.v1.pipeline import pipeline\n",
    "\n",
    "model_type = \"gb\"\n",
    "gb_results = pipeline(X_train, X_test, y_train, y_test, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/model_v1/scaler.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save artifacts\n",
    "\n",
    "joblib.dump(gb_results['model'], ARTIFACT_PATH + \"model.pkl\")\n",
    "joblib.dump(scaler, ARTIFACT_PATH + \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python) Especialista AI",
   "language": "python",
   "name": "esp_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
