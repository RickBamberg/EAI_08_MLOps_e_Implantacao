{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, f1_score, \n",
    "    precision_score, recall_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] O sistema não pode encontrar o arquivo especificado: 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msrc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m carregar_dados\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.getcwd())\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] O sistema não pode encontrar o arquivo especificado: 'src'"
     ]
    }
   ],
   "source": [
    "os.chdir('src')\n",
    "from data.load_data import carregar_dados\n",
    "\n",
    "print(os.getcwd())\n",
    "df = carregar_dados(\"../data/raw/v1/bs140513_032310.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição da variável target\n",
    "fraud_counts = df['fraud'].value_counts().sort_index()\n",
    "fraud_pct = df['fraud'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "for value in sorted(df['fraud'].unique()):\n",
    "    count = fraud_counts[value]\n",
    "    pct = fraud_pct[value]\n",
    "    label = 'Normal' if value == 0 else 'Fraude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataframe para feature engineering\n",
    "df_features = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. FEATURES BASEADAS NO CLIENTE\n",
    "# ============================================================================\n",
    "\n",
    "# Frequência de transações por cliente no mesmo step\n",
    "freq_step = (\n",
    "    df_features.groupby(['step', 'customer'])\n",
    "    .size()\n",
    "    .reset_index(name='qtd_transacoes')\n",
    ")\n",
    "df_features = df_features.merge(freq_step, on=['step', 'customer'])\n",
    "df_features['alert_freq'] = (df_features['qtd_transacoes'] > 3).astype(int)\n",
    "\n",
    "# Perfil de valor por cliente (média e desvio padrão)\n",
    "stats_cliente = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "stats_cliente.columns = ['customer', 'amount_mean_cliente', 'amount_std_cliente']\n",
    "df_features = df_features.merge(stats_cliente, on='customer')\n",
    "df_features['amount_std_cliente'].fillna(0, inplace=True)\n",
    "df_features['alert_valor'] = (\n",
    "    df_features['amount'] > (df_features['amount_mean_cliente'] + 3 * df_features['amount_std_cliente'])\n",
    ").astype(int)\n",
    "\n",
    "# Valor relativo à média do cliente\n",
    "df_features['valor_relativo_cliente'] = df_features['amount'] / (df_features['amount_mean_cliente'] + 1e-6)\n",
    "\n",
    "# Total de transações por cliente\n",
    "df_features['total_tx_cliente'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "# Volume total gasto pelo cliente\n",
    "df_features['volume_total_cliente'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform('sum')\n",
    ")\n",
    "\n",
    "# Diversidade de categorias por cliente\n",
    "df_features['num_categorias_cliente'] = (\n",
    "    df_features.groupby('customer')['category']\n",
    "    .transform('nunique')\n",
    ")\n",
    "\n",
    "# Diversidade de merchants por cliente\n",
    "df_features['num_merchants_cliente'] = (\n",
    "    df_features.groupby('customer')['merchant']\n",
    "    .transform('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. FEATURES TEMPORAIS\n",
    "# ============================================================================\n",
    "\n",
    "# Ordenando por cliente e step\n",
    "df_features = df_features.sort_values(['customer', 'step']).reset_index(drop=True)\n",
    "\n",
    "# Transações nos últimos 5 steps\n",
    "df_features['tx_ultimos_5_steps'] = (\n",
    "    df_features.groupby('customer')['step']\n",
    "    .transform(lambda x: x.rolling(5, min_periods=1).count())\n",
    ")\n",
    "\n",
    "# Tempo desde a última transação\n",
    "df_features['step_diff'] = (\n",
    "    df_features.groupby('customer')['step']\n",
    "    .diff()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Média de valor dos últimos 5 steps\n",
    "df_features['amount_media_5steps'] = (\n",
    "    df_features.groupby('customer')['amount']\n",
    "    .transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Desvio do valor atual em relação aos últimos 5 steps\n",
    "df_features['amount_desvio_5steps'] = (\n",
    "    df_features['amount'] - df_features['amount_media_5steps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. FEATURES DE RELACIONAMENTO CLIENTE-MERCHANT\n",
    "# ============================================================================\n",
    "\n",
    "# Frequência do par cliente-merchant\n",
    "df_features['tx_cliente_merchant'] = (\n",
    "    df_features.groupby(['customer', 'merchant'])['amount']\n",
    "    .transform('count')\n",
    ")\n",
    "\n",
    "# É a primeira transação deste cliente com este merchant?\n",
    "df_features['primeira_tx_merchant'] = (\n",
    "    df_features['tx_cliente_merchant'] == 1\n",
    ").astype(int)\n",
    "\n",
    "# Proporção de transações do cliente neste merchant\n",
    "df_features['prop_tx_merchant'] = (\n",
    "    df_features['tx_cliente_merchant'] / df_features['total_tx_cliente']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. FEATURES DE LOCALIZAÇÃO\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Mesma localização?\n",
    "df_features['mesma_localizacao'] = (\n",
    "    df_features['zipcodeOri'] == df_features['zipMerchant']\n",
    ").astype(int)\n",
    "\n",
    "# Número de diferentes localizações do cliente\n",
    "df_features['num_zipcodes_cliente'] = (\n",
    "    df_features.groupby('customer')['zipcodeOri']\n",
    "    .transform('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding de variáveis categóricas\n",
    "le_gender = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "\n",
    "df_features['gender_encoded'] = le_gender.fit_transform(df_features['gender'])\n",
    "df_features['category_encoded'] = le_category.fit_transform(df_features['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando features para o modelo\n",
    "features_to_use = [\n",
    "    # Features originais\n",
    "    'step', 'age', 'gender_encoded', 'category_encoded', 'amount',\n",
    "    \n",
    "    # Features engineered - Cliente\n",
    "    'qtd_transacoes', 'alert_freq', 'alert_valor', 'valor_relativo_cliente',\n",
    "    'total_tx_cliente', 'volume_total_cliente', 'num_categorias_cliente',\n",
    "    'num_merchants_cliente', 'amount_mean_cliente', 'amount_std_cliente',\n",
    "    \n",
    "    # Features temporais\n",
    "    'tx_ultimos_5_steps', 'step_diff', 'amount_media_5steps', 'amount_desvio_5steps',\n",
    "    \n",
    "    # Features merchant\n",
    "    #'tx_por_merchant_train', 'fraude_merchant_train', 'amount_mean_merchant'\n",
    "     'amount_std_merchant',\n",
    "    \n",
    "    # Features relacionamento\n",
    "    'tx_cliente_merchant', 'primeira_tx_merchant', 'prop_tx_merchant',\n",
    "    \n",
    "    # Features localização\n",
    "    'mesma_localizacao', 'num_zipcodes_cliente',\n",
    "    \n",
    "    # Features categoria\n",
    "    #'fraude_categoria'\n",
    "     'amount_mean_categoria', 'amount_desvio_categoria',\n",
    "    \n",
    "    # Scores\n",
    "    'qtd_alertas', 'score_regra'\n",
    "]\n",
    "\n",
    "# Verificar se todas as features existem\n",
    "missing_features = [f for f in features_to_use if f not in df_features.columns]\n",
    "if missing_features:\n",
    "    features_to_use = [f for f in features_to_use if f in df_features.columns]\n",
    "\n",
    "X = df_features[features_to_use].copy()\n",
    "y = df_features['fraud'].copy()\n",
    "\n",
    "# Garantir que X contém apenas valores numéricos\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Substituir inf e -inf por NaN\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Preencher NaN com 0\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/teste com estratificação\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização das features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar modelos\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Treina e avalia um modelo de classificação\"\"\"\n",
    "    \n",
    "    # Treinamento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predições\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'cm': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "lr_results = evaluate_model(\n",
    "    lr_model, X_train_scaled, X_test_scaled, y_train, y_test,\n",
    "    \"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_results = evaluate_model(\n",
    "    rf_model, X_train, X_test, y_train, y_test,\n",
    "    \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Treinando: Gradient Boosting\n",
      "============================================================\n",
      "\n",
      "Métricas no conjunto de teste:\n",
      "  Precision: 0.9180\n",
      "  Recall:    0.8007\n",
      "  F1-Score:  0.8553\n",
      "  ROC-AUC:   0.9982\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[117386    103]\n",
      " [   287   1153]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    117489\n",
      "      Fraude       0.92      0.80      0.86      1440\n",
      "\n",
      "    accuracy                           1.00    118929\n",
      "   macro avg       0.96      0.90      0.93    118929\n",
      "weighted avg       1.00      1.00      1.00    118929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_results = evaluate_model(\n",
    "    gb_model, X_train, X_test, y_train, y_test,\n",
    "    \"Gradient Boosting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARAÇÃO DE MODELOS\n",
      "======================================================================\n",
      "              Model  Precision   Recall  F1-Score  ROC-AUC\n",
      "Logistic Regression   0.246814 0.981944  0.394476 0.995627\n",
      "      Random Forest   0.730546 0.873611  0.795699 0.998023\n",
      "  Gradient Boosting   0.917994 0.800694  0.855341 0.998225\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comparação de métricas\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Precision': [lr_results['precision'], rf_results['precision'], gb_results['precision']],\n",
    "    'Recall': [lr_results['recall'], rf_results['recall'], gb_results['recall']],\n",
    "    'F1-Score': [lr_results['f1'], rf_results['f1'], gb_results['f1']],\n",
    "    'ROC-AUC': [lr_results['roc_auc'], rf_results['roc_auc'], gb_results['roc_auc']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAÇÃO DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
